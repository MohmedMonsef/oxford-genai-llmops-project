[{"title": "LLM Magnons", "summary": "We consider excitations of LLM geometries described by coloring the LLM plane\nwith concentric black rings. Certain closed string excitations are localized at\nthe edges of these rings. The string theory predictions for the energies of\nmagnon excitations of these strings depends on the radii of the edges of the\nrings. In this article we construct the operators dual to these closed string\nexcitations and show how to reproduce the string theory predictions for magnon\nenergies by computing one loop anomalous dimensions. These operators are linear\ncombinations of restricted Schur polynomials. The distinction between what is\nthe background and what is the excitation is accomplished in the choice of the\nsubgroup and the representations used to construct the operator."}, {"title": "LLM-SQL-Solver: Can LLMs Determine SQL Equivalence?", "summary": "Judging the equivalence between two SQL queries is a fundamental problem with\nmany practical applications in data management and SQL generation (i.e.,\nevaluating the quality of generated SQL queries in text-to-SQL task). While the\nresearch community has reasoned about SQL equivalence for decades, it poses\nconsiderable difficulties and no complete solutions exist. Recently, Large\nLanguage Models (LLMs) have shown strong reasoning capability in conversation,\nquestion answering and solving mathematics challenges. In this paper, we study\nif LLMs can be used to determine the equivalence between SQL queries under two\nnotions of SQL equivalence (semantic equivalence and relaxed equivalence). To\nassist LLMs in generating high quality responses, we present two prompting\ntechniques: Miniature & Mull and Explain & Compare. The former technique is\nused to evaluate the semantic equivalence in which it asks LLMs to execute a\nquery on a simple database instance and then explore if a counterexample exists\nby modifying the database. The latter technique is used to evaluate the relaxed\nequivalence in which it asks LLMs to explain the queries and then compare if\nthey contain significant logical differences. Our experiments demonstrate using\nour techniques, LLMs is a promising tool to help data engineers in writing\nsemantically equivalent SQL queries, however challenges still persist, and is a\nbetter metric for evaluating SQL generation than the popular execution\naccuracy."}, {"title": "LLM Augmented LLMs: Expanding Capabilities through Composition", "summary": "Foundational models with billions of parameters which have been trained on\nlarge corpora of data have demonstrated non-trivial skills in a variety of\ndomains. However, due to their monolithic structure, it is challenging and\nexpensive to augment them or impart new skills. On the other hand, due to their\nadaptation abilities, several new instances of these models are being trained\ntowards new domains and tasks. In this work, we study the problem of efficient\nand practical composition of existing foundation models with more specific\nmodels to enable newer capabilities. To this end, we propose CALM --\nComposition to Augment Language Models -- which introduces cross-attention\nbetween models to compose their representations and enable new capabilities.\nSalient features of CALM are: (i) Scales up LLMs on new tasks by 're-using'\nexisting LLMs along with a few additional parameters and data, (ii) Existing\nmodel weights are kept intact, and hence preserves existing capabilities, and\n(iii) Applies to diverse domains and settings. We illustrate that augmenting\nPaLM2-S with a smaller model trained on low-resource languages results in an\nabsolute improvement of up to 13\\% on tasks like translation into English and\narithmetic reasoning for low-resource languages. Similarly, when PaLM2-S is\naugmented with a code-specific model, we see a relative improvement of 40\\%\nover the base model for code generation and explanation tasks -- on-par with\nfully fine-tuned counterparts."}, {"title": "LLM Critics Help Catch LLM Bugs", "summary": "Reinforcement learning from human feedback (RLHF) is fundamentally limited by\nthe capacity of humans to correctly evaluate model output. To improve human\nevaluation ability and overcome that limitation this work trains \"critic\"\nmodels that help humans to more accurately evaluate model-written code. These\ncritics are themselves LLMs trained with RLHF to write natural language\nfeedback highlighting problems in code from real-world assistant tasks. On code\ncontaining naturally occurring LLM errors model-written critiques are preferred\nover human critiques in 63% of cases, and human evaluation finds that models\ncatch more bugs than human contractors paid for code review. We further confirm\nthat our fine-tuned LLM critics can successfully identify hundreds of errors in\nChatGPT training data rated as \"flawless\", even though the majority of those\ntasks are non-code tasks and thus out-of-distribution for the critic model.\nCritics can have limitations of their own, including hallucinated bugs that\ncould mislead humans into making mistakes they might have otherwise avoided,\nbut human-machine teams of critics and contractors catch similar numbers of\nbugs to LLM critics while hallucinating less than LLMs alone."}, {"title": "LLMs + Persona-Plug = Personalized LLMs", "summary": "Personalization plays a critical role in numerous language tasks and\napplications, since users with the same requirements may prefer diverse outputs\nbased on their individual interests. This has led to the development of various\npersonalized approaches aimed at adapting large language models (LLMs) to\ngenerate customized outputs aligned with user preferences. Some of them involve\nfine-tuning a unique personalized LLM for each user, which is too expensive for\nwidespread application. Alternative approaches introduce personalization\ninformation in a plug-and-play manner by retrieving the user's relevant\nhistorical texts as demonstrations. However, this retrieval-based strategy may\nbreak the continuity of the user history and fail to capture the user's overall\nstyles and patterns, hence leading to sub-optimal performance. To address these\nchallenges, we propose a novel personalized LLM model, \\ours{}. It constructs a\nuser-specific embedding for each individual by modeling all her historical\ncontexts through a lightweight plug-in user embedder module. By attaching this\nembedding to the task input, LLMs can better understand and capture user habits\nand preferences, thereby producing more personalized outputs without tuning\ntheir own parameters. Extensive experiments on various tasks in the language\nmodel personalization (LaMP) benchmark demonstrate that the proposed model\nsignificantly outperforms existing personalized LLM approaches."}, {"title": "Beyond LLM in M-theory", "summary": "The Lin, Lunin, Maldacena (LLM) ansatz in D = 11 supports two independent\nKilling directions when a general Killing spinor ansatz is considered. Here we\nshow that these directions always commute, identify when the Killing spinors\nare charged, and show that both their inner product and resulting geometry are\ngoverned by two fundamental constants. In particular, setting one constant to\nzero leads to AdS7 x S4, setting the other to zero gives AdS4 x S7, while flat\nspacetime is recovered when both these constants are zero. Furthermore, when\nthe constants are equal, the spacetime is either LLM, or it corresponds to the\nKowalski-Glikman solution where the constants are simply the mass parameter."}, {"title": "Exciting LLM Geometries", "summary": "We study excitations of LLM geometries. These geometries arise from the\nbackreaction of a condensate of giant gravitons. Excitations of the condensed\nbranes are open strings, which give rise to an emergent Yang-Mills theory at\nlow energy. We study the dynamics of the planar limit of these emergent gauge\ntheories, accumulating evidence that they are planar ${\\cal N}=4$ super\nYang-Mills. There are three observations supporting this conclusion: (i) we\nargue for an isomorphism between the planar Hilbert space of the original\n${\\cal N}=4$ super Yang-Mills and the planar Hilbert space of the emergent\ngauge theory, (ii) we argue that the OPE coefficients of the planar limit of\nthe emergent gauge theory vanish and (iii) we argue that the planar spectrum of\nanomalous dimensions of the emergent gauge theory is that of planar ${\\cal\nN}=4$ super Yang-Mills. Despite the fact that the planar limit of the emergent\ngauge theory is planar ${\\cal N}=4$ super Yang-Mills, we explain why the\nemergent gauge theory is not ${\\cal N}=4$ super Yang-Mills theory."}, {"title": "Chaotic LLM billiards", "summary": "We study null geodesics of the ten-dimensional LLM geometries. In particular,\nwe show that there are a subset of these null geodesics that are confined to\nthe LLM plane. The effective dynamics of these in-plane geodesics is that of a\nHamiltonian system with two degrees of freedom (a phase space of dimension 4).\nWe show that these are chaotic. In the two-coloring of the LLM plane, if they\nstart in the empty region, they cannot penetrate the filled region and\nviceversa. The dynamical problem is therefore very similar to that of a\nbilliards problem with fixed obstacles. We study to what extent LLM geometries\nwith many droplets may be treated as an incipient black hole and draw analogies\nwith the fuzzball proposal.\n  We argue that for in-plane null geodesics deep in the interior of a region\nwith a lot of droplets, in order to exit towards the $AdS$ boundary they will\nneed to undergo a process that resembles diffusion. This mechanism can account\nfor signals getting lost in the putative black hole for a very long time."}, {"title": "LLM As DBA", "summary": "Database administrators (DBAs) play a crucial role in managing, maintaining\nand optimizing a database system to ensure data availability, performance, and\nreliability. However, it is hard and tedious for DBAs to manage a large number\nof database instances (e.g., millions of instances on the cloud databases).\nRecently large language models (LLMs) have shown great potential to understand\nvaluable documents and accordingly generate reasonable answers. Thus, we\npropose D-Bot, a LLM-based database administrator that can continuously acquire\ndatabase maintenance experience from textual sources, and provide reasonable,\nwell-founded, in-time diagnosis and optimization advice for target databases.\nThis paper presents a revolutionary LLM-centric framework for database\nmaintenance, including (i) database maintenance knowledge detection from\ndocuments and tools, (ii) tree of thought reasoning for root cause analysis,\nand (iii) collaborative diagnosis among multiple LLMs. Our preliminary\nexperimental results that D-Bot can efficiently and effectively diagnose the\nroot causes and our code is available at\ngithub.com/TsinghuaDatabaseGroup/DB-GPT."}, {"title": "Calibrating LLM-Based Evaluator", "summary": "Recent advancements in large language models (LLMs) on language modeling and\nemergent capabilities make them a promising reference-free evaluator of natural\nlanguage generation quality, and a competent alternative to human evaluation.\nHowever, hindered by the closed-source or high computational demand to host and\ntune, there is a lack of practice to further calibrate an off-the-shelf\nLLM-based evaluator towards better human alignment. In this work, we propose\nAutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate\nand align an LLM-based evaluator toward human preference. Instead of explicitly\nmodeling human preferences, we first implicitly encompass them within a set of\nhuman labels. Then, an initial set of scoring criteria is drafted by the\nlanguage model itself, leveraging in-context learning on different few-shot\nexamples. To further calibrate this set of criteria, we select the best\nperformers and re-draft them with self-refinement. Our experiments on multiple\ntext quality evaluation datasets illustrate a significant improvement in\ncorrelation with expert evaluation through calibration. Our comprehensive\nqualitative analysis conveys insightful intuitions and observations on the\nessence of effective scoring criteria."}, {"title": "Constituency Parsing using LLMs", "summary": "Constituency parsing is a fundamental yet unsolved natural language\nprocessing task. In this paper, we explore the potential of recent large\nlanguage models (LLMs) that have exhibited remarkable performance across\nvarious domains and tasks to tackle this task. We employ three linearization\nstrategies to transform output trees into symbol sequences, such that LLMs can\nsolve constituency parsing by generating linearized trees. We conduct\nexperiments using a diverse range of LLMs, including ChatGPT, GPT-4, OPT,\nLLaMA, and Alpaca, comparing their performance against the state-of-the-art\nconstituency parsers. Our experiments encompass zero-shot, few-shot, and\nfull-training learning settings, and we evaluate the models on one in-domain\nand five out-of-domain test datasets. Our findings reveal insights into LLMs'\nperformance, generalization abilities, and challenges in constituency parsing."}, {"title": "LLMs-augmented Contextual Bandit", "summary": "Contextual bandits have emerged as a cornerstone in reinforcement learning,\nenabling systems to make decisions with partial feedback. However, as contexts\ngrow in complexity, traditional bandit algorithms can face challenges in\nadequately capturing and utilizing such contexts. In this paper, we propose a\nnovel integration of large language models (LLMs) with the contextual bandit\nframework. By leveraging LLMs as an encoder, we enrich the representation of\nthe context, providing the bandit with a denser and more informative view.\nPreliminary results on synthetic datasets demonstrate the potential of this\napproach, showing notable improvements in cumulative rewards and reductions in\nregret compared to traditional bandit algorithms. This integration not only\nshowcases the capabilities of LLMs in reinforcement learning but also opens the\ndoor to a new era of contextually-aware decision systems."}, {"title": "LLM Augmented Hierarchical Agents", "summary": "Solving long-horizon, temporally-extended tasks using Reinforcement Learning\n(RL) is challenging, compounded by the common practice of learning without\nprior knowledge (or tabula rasa learning). Humans can generate and execute\nplans with temporally-extended actions and quickly learn to perform new tasks\nbecause we almost never solve problems from scratch. We want autonomous agents\nto have this same ability. Recently, LLMs have been shown to encode a\ntremendous amount of knowledge about the world and to perform impressive\nin-context learning and reasoning. However, using LLMs to solve real world\nproblems is hard because they are not grounded in the current task. In this\npaper we exploit the planning capabilities of LLMs while using RL to provide\nlearning from the environment, resulting in a hierarchical agent that uses LLMs\nto solve long-horizon tasks. Instead of completely relying on LLMs, they guide\na high-level policy, making learning significantly more sample efficient. This\napproach is evaluated in simulation environments such as MiniGrid, SkillHack,\nand Crafter, and on a real robot arm in block manipulation tasks. We show that\nagents trained using our approach outperform other baselines methods and, once\ntrained, don't need access to LLMs during deployment."}, {"title": "The LLM Surgeon", "summary": "State-of-the-art language models are becoming increasingly large in an effort\nto achieve the highest performance on large corpora of available textual data.\nHowever, the sheer size of the Transformer architectures makes it difficult to\ndeploy models within computational, environmental or device-specific\nconstraints. We explore data-driven compression of existing pretrained models\nas an alternative to training smaller models from scratch. To do so, we scale\nKronecker-factored curvature approximations of the target loss landscape to\nlarge language models. In doing so, we can compute both the dynamic allocation\nof structures that can be removed as well as updates of remaining weights that\naccount for the removal. We provide a general framework for unstructured,\nsemi-structured and structured pruning and improve upon weight updates to\ncapture more correlations between weights, while remaining computationally\nefficient. Experimentally, our method can prune rows and columns from a range\nof OPT models and Llamav2-7B by 20%-30%, with a negligible loss in performance,\nand achieve state-of-the-art results in unstructured and semi-structured\npruning of large language models."}, {"title": "Efficient Exploration for LLMs", "summary": "We present evidence of substantial benefit from efficient exploration in\ngathering human feedback to improve large language models. In our experiments,\nan agent sequentially generates queries while fitting a reward model to the\nfeedback received. Our best-performing agent generates queries using double\nThompson sampling, with uncertainty represented by an epistemic neural network.\nOur results demonstrate that efficient exploration enables high levels of\nperformance with far fewer queries. Further, both uncertainty estimation and\nthe choice of exploration scheme play critical roles."}, {"title": "LLM-Enhanced Data Management", "summary": "Machine learning (ML) techniques for optimizing data management problems have\nbeen extensively studied and widely deployed in recent five years. However\ntraditional ML methods have limitations on generalizability (adapting to\ndifferent scenarios) and inference ability (understanding the context).\nFortunately, large language models (LLMs) have shown high generalizability and\nhuman-competitive abilities in understanding context, which are promising for\ndata management tasks (e.g., database diagnosis, database tuning). However,\nexisting LLMs have several limitations: hallucination, high cost, and low\naccuracy for complicated tasks. To address these challenges, we design LLMDB,\nan LLM-enhanced data management paradigm which has generalizability and high\ninference ability while avoiding hallucination, reducing LLM cost, and\nachieving high accuracy. LLMDB embeds domain-specific knowledge to avoid\nhallucination by LLM fine-tuning and prompt engineering. LLMDB reduces the high\ncost of LLMs by vector databases which provide semantic search and caching\nabilities. LLMDB improves the task accuracy by LLM agent which provides\nmultiple-round inference and pipeline executions. We showcase three real-world\nscenarios that LLMDB can well support, including query rewrite, database\ndiagnosis and data analytics. We also summarize the open research challenges of\nLLMDB."}, {"title": "Scaling Efficient LLMs", "summary": "Trained LLMs are typically sparse in that most of the parameters are zero,\nraising questions on efficiency. In response, we inquire into efficient LLMs,\ni.e. those with the fewest parameters that achieve the desired accuracy on a\ntraining corpus. Specifically, we compare theoretical and empirical estimates\nfor training loss to obtain upper and lower bounds on the number of unique\nsequences in a natural training corpus as a function of its size. Our result\nimplies (1) to double the number of skills represented in a training corpus,\nthe corpus must scale more than four fold (2) for efficient LLMs, the number of\nparameters N and the size D of a natural training corpus scale as $N \\propto\nD^{0.44}$; (3) if the number of parameters of an LLM is smaller than the number\nof unique sequences in the training corpus, scaling up can uncover emergent\nskills."}, {"title": "VBART: The Turkish LLM", "summary": "We present VBART, the first Turkish sequence-to-sequence Large Language\nModels (LLMs) pre-trained on a large corpus from scratch. VBART are compact\nLLMs based on good ideas leveraged from BART and mBART models and come in two\nsizes, Large and XLarge. Fine-tuned VBART models surpass the prior\nstate-of-the-art results in abstractive text summarization, title generation,\ntext paraphrasing, question answering and question generation tasks. They allow\nfine-tuning for future text generation tasks and datasets, carving a new path\nfor Turkish Natural Language Processing (NLP) research. Our work shows that\nhaving a pre-trained LLM for Turkish outperforms up to 3x multilingual models,\nimproving existing results and providing efficient models for training and\ninference. Moreover, we show that our monolingual tokenizer is up to 11x more\nefficient than multilingual tokenizers. Last but not least, we introduce a\nmethod to enlarge an existing pre-trained LLM and question the relevancy of\nChinchilla Scaling Law to sequence-to-sequence masked language models. Our\nfine-tuned models, tokenizer and cleaned vngrs-web-corpus of 135 GB are\npublicly available at huggingface.co/vngrs-ai."}, {"title": "LLM-Oriented Retrieval Tuner", "summary": "Dense Retrieval (DR) is now considered as a promising tool to enhance the\nmemorization capacity of Large Language Models (LLM) such as GPT3 and GPT-4 by\nincorporating external memories. However, due to the paradigm discrepancy\nbetween text generation of LLM and DR, it is still an open challenge to\nintegrate the retrieval and generation tasks in a shared LLM. In this paper, we\npropose an efficient LLM-Oriented Retrieval Tuner, namely LMORT, which\ndecouples DR capacity from base LLM and non-invasively coordinates the\noptimally aligned and uniform layers of the LLM towards a unified DR space,\nachieving an efficient and effective DR without tuning the LLM itself. The\nextensive experiments on six BEIR datasets show that our approach could achieve\ncompetitive zero-shot retrieval performance compared to a range of strong DR\nmodels while maintaining the generation ability of LLM."}, {"title": "Auctions with LLM Summaries", "summary": "We study an auction setting in which bidders bid for placement of their\ncontent within a summary generated by a large language model (LLM), e.g., an ad\nauction in which the display is a summary paragraph of multiple ads. This\ngeneralizes the classic ad settings such as position auctions to an LLM\ngenerated setting, which allows us to handle general display formats. We\npropose a novel factorized framework in which an auction module and an LLM\nmodule work together via a prediction model to provide welfare maximizing\nsummary outputs in an incentive compatible manner. We provide a theoretical\nanalysis of this framework and synthetic experiments to demonstrate the\nfeasibility and validity of the system together with welfare comparisons."}]